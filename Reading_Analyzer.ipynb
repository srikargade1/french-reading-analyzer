{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b0d8dce-4df0-4abc-9a5b-04321d4dd01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENTENCE: Le chat noir dort sur le canapé.\n",
      "SENTENCE: Il rêve de poissons frais.\n",
      "Le → Le → 1\n",
      "chat → chat → 1\n",
      "noir → noir → 1\n",
      "dort → dort → 1\n",
      "sur → sur → 1\n",
      "le → le → 1\n",
      "canapé → ca-na-pé → 3\n",
      "Il → Il → 1\n",
      "rêve → rêve → 1\n",
      "de → de → 1\n",
      "poissons → pois-sons → 2\n",
      "frais → frais → 1\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pyphen\n",
    "\n",
    "# Load French NLP model\n",
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "\n",
    "# Sample test\n",
    "text = \"Le chat noir dort sur le canapé. Il rêve de poissons frais.\"\n",
    "doc = nlp(text)\n",
    "\n",
    "# Tokenization & sentence test\n",
    "for sent in doc.sents:\n",
    "    print(\"SENTENCE:\", sent.text)\n",
    "\n",
    "# Syllable test\n",
    "dic = pyphen.Pyphen(lang='fr')\n",
    "for token in doc:\n",
    "    if token.is_alpha:\n",
    "        print(token.text, \"→\", dic.inserted(token.text), \"→\", dic.inserted(token.text).count('-') + 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bf01d7f-afbf-4d11-b242-187c37cd8205",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_french_text(text):\n",
    "    nlp = spacy.load(\"fr_core_news_sm\")\n",
    "    dic = pyphen.Pyphen(lang='fr')\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    sentences = list(doc.sents)\n",
    "    \n",
    "    word_count = 0\n",
    "    syllable_count = 0\n",
    "    complex_words = []\n",
    "    \n",
    "    for token in doc:\n",
    "        if token.is_alpha:\n",
    "            word = token.text\n",
    "            word_count += 1\n",
    "            syllables = dic.inserted(word).count('-') + 1\n",
    "            syllable_count += syllables\n",
    "            if syllables >= 3:\n",
    "                complex_words.append(word)\n",
    "    \n",
    "    sentence_count = len(sentences)\n",
    "    \n",
    "    # Flesch Reading Ease (French version)\n",
    "    # Formula adapted: 207 - (1.015 * ASL) - (73.6 * ASW)\n",
    "    ASL = word_count / sentence_count if sentence_count else 0  # Average Sentence Length\n",
    "    ASW = syllable_count / word_count if word_count else 0      # Average Syllables per Word\n",
    "    flesch_score = 207 - (1.015 * ASL) - (73.6 * ASW)\n",
    "    \n",
    "    return {\n",
    "        \"word_count\": word_count,\n",
    "        \"sentence_count\": sentence_count,\n",
    "        \"syllable_count\": syllable_count,\n",
    "        \"flesch_score\": round(flesch_score, 2),\n",
    "        \"complex_words\": complex_words\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d572c52-0dc5-4d22-8804-f833320c51a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'word_count': 12, 'sentence_count': 2, 'syllable_count': 15, 'flesch_score': 108.91, 'complex_words': ['canapé']}\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"Le chat noir dort sur le canapé. Il rêve de poissons frais.\"\n",
    "result = analyze_french_text(sample_text)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4733313a-50f6-472c-a0ac-924ca6cd0e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample CEFR word list for French (expand this later)\n",
    "cefr_vocab = {\n",
    "    \"le\": \"A1\", \"chat\": \"A1\", \"noir\": \"A1\", \"dort\": \"A2\",\n",
    "    \"sur\": \"A1\", \"canapé\": \"B1\", \"rêve\": \"B2\", \"de\": \"A1\",\n",
    "    \"poissons\": \"A2\", \"frais\": \"B1\", \"il\": \"A1\", \"manger\": \"A2\",\n",
    "    \"parce\": \"A1\", \"que\": \"A1\", \"chien\": \"A1\", \"cuisine\": \"B1\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "954d7324-91e5-4b5d-8dbf-16089262d486",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_cefr_vocab(text, vocab_map):\n",
    "    nlp = spacy.load(\"fr_core_news_sm\")\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    cefr_counts = {\n",
    "        \"A1\": 0, \"A2\": 0, \"B1\": 0,\n",
    "        \"B2\": 0, \"C1\": 0, \"C2\": 0,\n",
    "        \"Unknown\": 0\n",
    "    }\n",
    "    \n",
    "    word_levels = {}\n",
    "\n",
    "    for token in doc:\n",
    "        if token.is_alpha:\n",
    "            word = token.text.lower()\n",
    "            level = vocab_map.get(word, \"Unknown\")\n",
    "            cefr_counts[level] += 1\n",
    "            word_levels[word] = level\n",
    "    \n",
    "    # Estimate CEFR based on most frequent *non-A1* level\n",
    "    levels_ranked = [\"C2\", \"C1\", \"B2\", \"B1\", \"A2\", \"A1\"]\n",
    "    estimated = max(\n",
    "        (lvl for lvl in levels_ranked if cefr_counts[lvl] > 0),\n",
    "        key=lambda lvl: cefr_counts[lvl],\n",
    "        default=\"A1\"\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"word_levels\": word_levels,\n",
    "        \"cefr_distribution\": cefr_counts,\n",
    "        \"estimated_cefr_level\": estimated\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "617265c7-ddfd-4673-b788-bf837c6e565e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'word_levels': {'le': 'A1', 'chat': 'A1', 'noir': 'A1', 'dort': 'A2', 'sur': 'A1', 'canapé': 'B1', 'il': 'A1', 'rêve': 'B2', 'de': 'A1', 'poissons': 'A2', 'frais': 'B1'}, 'cefr_distribution': {'A1': 7, 'A2': 2, 'B1': 2, 'B2': 1, 'C1': 0, 'C2': 0, 'Unknown': 0}, 'estimated_cefr_level': 'A1'}\n"
     ]
    }
   ],
   "source": [
    "text = \"Le chat noir dort sur le canapé. Il rêve de poissons frais.\"\n",
    "\n",
    "cefr_result = analyze_cefr_vocab(text, vocab_map=cefr_vocab)\n",
    "print(cefr_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb950df7-db3c-409a-bcba-e9ba0c2b442b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_text_analysis(text, vocab_map):\n",
    "    readability = analyze_french_text(text)\n",
    "    cefr = analyze_cefr_vocab(text, vocab_map)\n",
    "    \n",
    "    return {\n",
    "        \"readability\": readability,\n",
    "        \"cefr\": cefr\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3726238-621b-40f6-87d5-50d286f8a082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " L’Algérie a refusé, lundi 17 mars, la liste des noms d’une soixantaine d’Algériens à expulser que la France lui a soumise il y a quelques jours, une démarche « rejetée sur la forme et le fond » par Alger. « Les autorités algériennes ont décidé de ne pas donner suite à la liste soumise par les autorités françaises » et les ont « invitées à suivre le canal d’usage, en l’occurrence celui établi entre les préfectures et les consulats », précise un communiqué du ministère des affaires étrangères.\n"
     ]
    }
   ],
   "source": [
    "text = input()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09e090cd-d95a-4158-a983-417c50692fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'readability': {'word_count': 81, 'sentence_count': 3, 'syllable_count': 127, 'flesch_score': 64.2, 'complex_words': ['Algérie', 'refusé', 'Algériens', 'expulser', 'rejetée', 'autorités', 'algériennes', 'décidé', 'autorités', 'invitées', 'occurrence', 'préfectures', 'communiqué', 'ministère']}, 'cefr': {'word_levels': {'algérie': 'Unknown', 'a': 'Unknown', 'refusé': 'Unknown', 'lundi': 'Unknown', 'mars': 'Unknown', 'la': 'Unknown', 'liste': 'Unknown', 'des': 'Unknown', 'noms': 'Unknown', 'une': 'Unknown', 'soixantaine': 'Unknown', 'algériens': 'Unknown', 'à': 'Unknown', 'expulser': 'Unknown', 'que': 'A1', 'france': 'Unknown', 'lui': 'Unknown', 'soumise': 'Unknown', 'il': 'A1', 'y': 'Unknown', 'quelques': 'Unknown', 'jours': 'Unknown', 'démarche': 'Unknown', 'rejetée': 'Unknown', 'sur': 'A1', 'forme': 'Unknown', 'et': 'Unknown', 'le': 'A1', 'fond': 'Unknown', 'par': 'Unknown', 'alger': 'Unknown', 'les': 'Unknown', 'autorités': 'Unknown', 'algériennes': 'Unknown', 'ont': 'Unknown', 'décidé': 'Unknown', 'de': 'A1', 'ne': 'Unknown', 'pas': 'Unknown', 'donner': 'Unknown', 'suite': 'Unknown', 'françaises': 'Unknown', 'invitées': 'Unknown', 'suivre': 'Unknown', 'canal': 'Unknown', 'usage': 'Unknown', 'en': 'Unknown', 'occurrence': 'Unknown', 'celui': 'Unknown', 'établi': 'Unknown', 'entre': 'Unknown', 'préfectures': 'Unknown', 'consulats': 'Unknown', 'précise': 'Unknown', 'un': 'Unknown', 'communiqué': 'Unknown', 'du': 'Unknown', 'ministère': 'Unknown', 'affaires': 'Unknown', 'étrangères': 'Unknown'}, 'cefr_distribution': {'A1': 6, 'A2': 0, 'B1': 0, 'B2': 0, 'C1': 0, 'C2': 0, 'Unknown': 75}, 'estimated_cefr_level': 'A1'}}\n"
     ]
    }
   ],
   "source": [
    "summary = summarize_text_analysis(text, vocab_map=cefr_vocab)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee6fc9e7-4aae-454f-9a75-38c45ba85a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading pandas-2.2.3-cp310-cp310-win_amd64.whl (11.6 MB)\n",
      "     --------------------------------------- 11.6/11.6 MB 13.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anaconda\\envs\\french_nlp\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in d:\\anaconda\\envs\\french_nlp\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\anaconda\\envs\\french_nlp\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting tzdata>=2022.7\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "     ------------------------------------- 347.8/347.8 kB 10.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.5 in d:\\anaconda\\envs\\french_nlp\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Installing collected packages: tzdata, pandas\n",
      "Successfully installed pandas-2.2.3 tzdata-2025.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1ff83f6-4f1f-48cd-a286-78176825d575",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_cefr_vocab_from_flelex(csv_path):\n",
    "    french_df = pd.read_csv(csv_path, sep=\"\\t\", encoding=\"utf-8\", engine=\"python\")\n",
    "    cefr_levels = ['A1', 'A2', 'B1', 'B2', 'C1', 'C2']\n",
    "    def infer_cefr_level(row):\n",
    "        freqs = [row[f'freq_{level}'] for level in cefr_levels]\n",
    "        max_index = freqs.index(max(freqs))\n",
    "        return cefr_levels[max_index]\n",
    "    french_df['inferred_cefr_level'] = french_df.apply(infer_cefr_level, axis=1)\n",
    "    \n",
    "    # Create dictionary: {word: inferred_cefr_level}\n",
    "    vocab_map = dict(zip(french_df['word'].str.lower(), french_df['inferred_cefr_level']))\n",
    "    \n",
    "    return vocab_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd509dea-8a4c-433b-a138-402718915881",
   "metadata": {},
   "outputs": [],
   "source": [
    "cefr_vocab = load_cefr_vocab_from_flelex(\"FLELex_TreeTagger.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8980aa28-c067-477d-a5e3-298f4d10cf4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'-ci': 'C1',\n",
       " 'abaisser': 'C2',\n",
       " 'abandon': 'C1',\n",
       " 'abandonner': 'B1',\n",
       " 'abasourdir': 'B2',\n",
       " 'abattage': 'C1',\n",
       " 'abattoir': 'C1',\n",
       " 'abattre': 'C1',\n",
       " 'abbaye': 'B1',\n",
       " 'abbé': 'B1',\n",
       " 'abeille': 'C2',\n",
       " 'aberration': 'C1',\n",
       " 'aboiement': 'B1',\n",
       " 'abolir': 'C1',\n",
       " 'abolition': 'C1',\n",
       " 'abomination': 'C1',\n",
       " 'abondamment': 'C1',\n",
       " 'abondance': 'B1',\n",
       " 'abondant': 'C2',\n",
       " 'abonder': 'B2',\n",
       " 'abonnement': 'A2',\n",
       " 'abonner': 'C1',\n",
       " 'abonné': 'C1',\n",
       " 'abord': 'C1',\n",
       " 'abordable': 'C1',\n",
       " 'aborder': 'C1',\n",
       " 'aborigène': 'A2',\n",
       " 'aboutir': 'C1',\n",
       " 'aboutissement': 'C2',\n",
       " 'aboyer': 'B1',\n",
       " 'abreuver': 'A2',\n",
       " 'abri': 'B1',\n",
       " 'abricot': 'A1',\n",
       " 'abriter': 'A2',\n",
       " 'abroger': 'C1',\n",
       " 'abruti': 'B2',\n",
       " 'abrutir': 'B1',\n",
       " 'abréger': 'B2',\n",
       " 'absence': 'C2',\n",
       " 'absent': 'C1',\n",
       " 'absenter': 'C2',\n",
       " 'absentéisme': 'B1',\n",
       " 'absolu': 'B2',\n",
       " 'absolument': 'A2',\n",
       " 'absorber': 'C1',\n",
       " 'absorption': 'C1',\n",
       " 'absoudre': 'B1',\n",
       " 'abstenir': 'C1',\n",
       " 'abstention': 'B1',\n",
       " 'abstraction': 'C2',\n",
       " 'abstraire': 'C1',\n",
       " 'absurde': 'B1',\n",
       " 'abus': 'C1',\n",
       " 'abuser': 'C1',\n",
       " 'abusif': 'C1',\n",
       " 'abyme': 'A2',\n",
       " 'abyssal': 'C1',\n",
       " 'abîme': 'C1',\n",
       " 'abîmer': 'B2',\n",
       " 'acacia': 'C2',\n",
       " 'académicien': 'B1',\n",
       " 'académie': 'B1',\n",
       " 'académique': 'C2',\n",
       " 'académisme': 'C1',\n",
       " 'accablant': 'B2',\n",
       " 'accabler': 'B1',\n",
       " 'accaparer': 'B2',\n",
       " 'accent': 'C2',\n",
       " 'accentuer': 'C2',\n",
       " 'acceptable': 'C1',\n",
       " 'acceptation': 'C1',\n",
       " 'accepter': 'B1',\n",
       " 'acception': 'C1',\n",
       " 'accessible': 'C1',\n",
       " 'accession': 'C2',\n",
       " 'accessoire': 'C2',\n",
       " 'accident': 'A1',\n",
       " 'accidentel': 'C1',\n",
       " 'accidenter': 'C1',\n",
       " 'acclamation': 'B1',\n",
       " 'acclamer': 'B1',\n",
       " 'acclimater': 'B1',\n",
       " 'accolade': 'A2',\n",
       " 'accoler': 'B2',\n",
       " 'accommoder': 'C1',\n",
       " 'accompagnement': 'C1',\n",
       " 'accompagner': 'A1',\n",
       " 'accomplir': 'C2',\n",
       " 'accomplissement': 'C2',\n",
       " 'accord': 'C2',\n",
       " 'accorder': 'C1',\n",
       " 'accordéon': 'B2',\n",
       " 'accoter': 'B1',\n",
       " 'accouchement': 'C1',\n",
       " 'accoucher': 'B1',\n",
       " 'accouder': 'B1',\n",
       " 'accourir': 'B2',\n",
       " 'accroc': 'B2',\n",
       " 'accrochage': 'B2',\n",
       " 'accroche': 'A2',\n",
       " 'accrocher': 'B1',\n",
       " 'accroire': 'B1',\n",
       " 'accroissement': 'B1',\n",
       " 'accroître': 'C2',\n",
       " 'accrue': 'C1',\n",
       " 'accréditer': 'C1',\n",
       " 'accueil': 'A1',\n",
       " 'accueillant': 'A1',\n",
       " 'accueillir': 'A1',\n",
       " 'accumulation': 'B2',\n",
       " 'accumuler': 'B1',\n",
       " 'accusateur': 'B1',\n",
       " 'accusation': 'B1',\n",
       " 'accuser': 'B2',\n",
       " 'accusé': 'B2',\n",
       " 'accès': 'C2',\n",
       " 'accéder': 'C2',\n",
       " 'accélérateur': 'C1',\n",
       " 'accélération': 'C2',\n",
       " 'accélérer': 'C1',\n",
       " 'accéléré': 'C1',\n",
       " 'acerbe': 'B2',\n",
       " 'acharnement': 'B2',\n",
       " 'acharner': 'B2',\n",
       " 'achat': 'C1',\n",
       " 'acheminement': 'B1',\n",
       " 'acheminer': 'C1',\n",
       " 'acheter': 'A1',\n",
       " 'acheteur': 'C1',\n",
       " 'achever': 'C2',\n",
       " 'achoppement': 'C1',\n",
       " 'acide': 'C2',\n",
       " 'acier': 'C1',\n",
       " 'acompte': 'C1',\n",
       " 'acoustique': 'C1',\n",
       " 'acquisition': 'C2',\n",
       " 'acquitter': 'C1',\n",
       " 'acquéreur': 'C1',\n",
       " 'acquérir': 'C2',\n",
       " 'acrobatie': 'B1',\n",
       " 'acrobatique': 'B1',\n",
       " 'acte': 'C2',\n",
       " 'acteur': 'C2',\n",
       " 'actif': 'C2',\n",
       " 'action': 'C1',\n",
       " 'actionnaire': 'C2',\n",
       " 'actionner': 'B1',\n",
       " 'activement': 'C1',\n",
       " 'activer': 'C2',\n",
       " 'activisme': 'C2',\n",
       " 'activité': 'C2',\n",
       " 'actualiser': 'B2',\n",
       " 'actualité': 'C2',\n",
       " 'actuel': 'C1',\n",
       " 'actuellement': 'C1',\n",
       " 'acétylcholine': 'C2',\n",
       " 'ad': 'B2',\n",
       " 'adage': 'C1',\n",
       " 'adaptable': 'A2',\n",
       " 'adaptation': 'A2',\n",
       " 'adapter': 'C2',\n",
       " 'additif': 'C1',\n",
       " 'addition': 'C1',\n",
       " 'adduction': 'B2',\n",
       " 'adepte': 'C1',\n",
       " 'adhérent': 'B1',\n",
       " 'adhérer': 'B1',\n",
       " 'adhésif': 'C1',\n",
       " 'adhésion': 'C2',\n",
       " 'adieu': 'B1',\n",
       " 'adjoindre': 'C2',\n",
       " 'adjoint': 'C2',\n",
       " 'adjudant': 'B1',\n",
       " 'adjuger': 'B1',\n",
       " 'adjurer': 'C1',\n",
       " 'adjuvant': 'B1',\n",
       " 'admettre': 'C2',\n",
       " 'administrateur': 'B2',\n",
       " 'administratif': 'C2',\n",
       " 'administration': 'C2',\n",
       " 'administrer': 'C1',\n",
       " 'admirable': 'A1',\n",
       " 'admirablement': 'B1',\n",
       " 'admirateur': 'B1',\n",
       " 'admiratif': 'C1',\n",
       " 'admiration': 'B2',\n",
       " 'admirer': 'A1',\n",
       " 'admission': 'B1',\n",
       " 'ado': 'A1',\n",
       " 'adolescence': 'B1',\n",
       " 'adolescent': 'C1',\n",
       " 'adonner': 'C2',\n",
       " 'adopter': 'C2',\n",
       " 'adoptif': 'A2',\n",
       " 'adoption': 'C1',\n",
       " 'adorable': 'A1',\n",
       " 'adorateur': 'B1',\n",
       " 'adoration': 'B1',\n",
       " 'adorer': 'A1',\n",
       " 'adosser': 'C1',\n",
       " 'adoubement': 'A1',\n",
       " 'adoucir': 'B1',\n",
       " 'adresse': 'A1',\n",
       " 'adresser': 'B1',\n",
       " 'adroit': 'A2',\n",
       " 'adroitement': 'A2',\n",
       " 'aduler': 'B1',\n",
       " 'adulte': 'A1',\n",
       " 'adultère': 'C1',\n",
       " 'adultérer': 'C1',\n",
       " 'advenir': 'C2',\n",
       " 'adversaire': 'C1',\n",
       " 'adversité': 'B1',\n",
       " 'adéquat': 'C2',\n",
       " 'affadissement': 'C1',\n",
       " 'affaiblir': 'C2',\n",
       " 'affaire': 'B2',\n",
       " 'affairer': 'B2',\n",
       " 'affaler': 'A2',\n",
       " 'affamer': 'B2',\n",
       " 'affamé': 'B1',\n",
       " 'affect': 'C2',\n",
       " 'affectation': 'C1',\n",
       " 'affecter': 'C1',\n",
       " 'affectif': 'B1',\n",
       " 'affection': 'C2',\n",
       " 'affectionner': 'B2',\n",
       " 'affectivement': 'B2',\n",
       " 'affectivité': 'B1',\n",
       " 'affectueusement': 'A2',\n",
       " 'affectueux': 'B1',\n",
       " 'affichage': 'C1',\n",
       " 'affiche': 'C1',\n",
       " 'afficher': 'C1',\n",
       " 'affilier': 'B1',\n",
       " 'affilée': 'B1',\n",
       " 'affiner': 'C1',\n",
       " 'affinité': 'B1',\n",
       " 'affirmatif': 'B1',\n",
       " 'affirmation': 'B2',\n",
       " 'affirmative': 'B1',\n",
       " 'affirmer': 'C2',\n",
       " 'affleurer': 'B2',\n",
       " 'affligeant': 'C1',\n",
       " 'affliger': 'B2',\n",
       " 'affluence': 'B1',\n",
       " 'affluent': 'A2',\n",
       " 'affluer': 'C2',\n",
       " 'afflux': 'B1',\n",
       " 'affolant': 'C1',\n",
       " 'affolement': 'C2',\n",
       " 'affoler': 'B1',\n",
       " 'affranchi': 'A2',\n",
       " 'affranchir': 'C1',\n",
       " 'affreusement': 'B1',\n",
       " 'affreux': 'A2',\n",
       " 'affront': 'B1',\n",
       " 'affrontement': 'C2',\n",
       " 'affronter': 'B1',\n",
       " 'affubler': 'B2',\n",
       " 'affût': 'B1',\n",
       " 'aficionado': 'B1',\n",
       " 'afin': 'C1',\n",
       " 'africain': 'B1',\n",
       " 'agacement': 'C1',\n",
       " 'agacer': 'B2',\n",
       " 'agaçant': 'A1',\n",
       " 'agence': 'C2',\n",
       " 'agenda': 'C2',\n",
       " 'agent': 'B2',\n",
       " 'aggiornamento': 'C1',\n",
       " 'agglomération': 'C1',\n",
       " 'agglutiner': 'B2',\n",
       " 'aggravation': 'C1',\n",
       " 'aggrave': 'B2',\n",
       " 'aggraver': 'C1',\n",
       " 'agile': 'B2',\n",
       " 'agilité': 'C2',\n",
       " 'agio': 'C1',\n",
       " 'agir': 'C2',\n",
       " 'agitation': 'A2',\n",
       " 'agiter': 'B1',\n",
       " 'agneau': 'C1',\n",
       " 'agoniser': 'C1',\n",
       " 'agora': 'B1',\n",
       " 'agoraphobie': 'B1',\n",
       " 'agrandir': 'B2',\n",
       " 'agrandissement': 'A2',\n",
       " 'agresser': 'C2',\n",
       " 'agresseur': 'C1',\n",
       " 'agressif': 'C1',\n",
       " 'agression': 'B2',\n",
       " 'agressivité': 'B2',\n",
       " 'agricole': 'C1',\n",
       " 'agriculteur': 'B1',\n",
       " 'agriculture': 'C1',\n",
       " 'agripper': 'B2',\n",
       " 'agro-alimentaire': 'C1',\n",
       " 'agroalimentaire': 'C1',\n",
       " 'agronome': 'C1',\n",
       " 'agronomie': 'C1',\n",
       " 'agronomique': 'C1',\n",
       " 'agrume': 'C2',\n",
       " 'agréable': 'B1',\n",
       " 'agréablement': 'A1',\n",
       " 'agréer': 'B2',\n",
       " 'agrégat': 'C1',\n",
       " 'agrégation': 'C1',\n",
       " 'agréger': 'B2',\n",
       " 'agrément': 'B2',\n",
       " 'agrémenter': 'B1',\n",
       " 'aguet': 'B2',\n",
       " 'aguicheur': 'C1',\n",
       " 'ah': 'A1',\n",
       " 'aicher': 'A1',\n",
       " 'aidant': 'A2',\n",
       " 'aide': 'C1',\n",
       " 'aider': 'A1',\n",
       " 'aigle': 'B1',\n",
       " 'aigre': 'B2',\n",
       " 'aigrelet': 'B2',\n",
       " 'aigrement': 'B1',\n",
       " 'aigreur': 'B2',\n",
       " 'aigu': 'C1',\n",
       " 'aigue-marine': 'B1',\n",
       " 'aiguille': 'A2',\n",
       " 'aiguiller': 'C1',\n",
       " 'aiguiser': 'B2',\n",
       " 'aiguë': 'C1',\n",
       " 'ail': 'A1',\n",
       " 'aile': 'A1',\n",
       " 'ailer': 'B1',\n",
       " 'ailler': 'B2',\n",
       " 'ailleurs': 'B1',\n",
       " 'aimable': 'B2',\n",
       " 'aimablement': 'B1',\n",
       " 'aimant': 'B1',\n",
       " 'aimer': 'A1',\n",
       " 'ainsi': 'C2',\n",
       " 'air': 'A2',\n",
       " 'airbus': 'C1',\n",
       " 'aire': 'C2',\n",
       " 'aisance': 'C1',\n",
       " 'aise': 'B1',\n",
       " 'aisé': 'C1',\n",
       " 'aisément': 'B2',\n",
       " 'ajourner': 'B2',\n",
       " 'ajout': 'C1',\n",
       " 'ajoute': 'A1',\n",
       " 'ajouter': 'C1',\n",
       " 'alambic': 'C1',\n",
       " 'alanguir': 'A2',\n",
       " 'alarmant': 'B2',\n",
       " 'alarme': 'C1',\n",
       " 'alarmer': 'B2',\n",
       " 'alarmiste': 'C1',\n",
       " 'albigeois': 'B1',\n",
       " 'albinos': 'A2',\n",
       " 'album': 'A2',\n",
       " 'albâtre': 'B1',\n",
       " 'alcool': 'B1',\n",
       " 'alcoolique': 'A1',\n",
       " 'alcooliser': 'B1',\n",
       " 'alcoolisme': 'C2',\n",
       " 'alcoolémie': 'A2',\n",
       " 'alcootest': 'A2',\n",
       " 'aldéhyde': 'C1',\n",
       " 'aldéhydé': 'C2',\n",
       " 'alentour': 'B2',\n",
       " 'alerte': 'C1',\n",
       " 'alerter': 'C1',\n",
       " 'alexandra': 'B1',\n",
       " 'algérien': 'C2',\n",
       " 'alibi': 'B2',\n",
       " 'alignement': 'B1',\n",
       " 'aligner': 'B1',\n",
       " 'aliment': 'B1',\n",
       " 'alimentaire': 'C1',\n",
       " 'alimentation': 'C2',\n",
       " 'alimenter': 'C1',\n",
       " 'alinéa': 'B1',\n",
       " 'aliénant': 'B1',\n",
       " 'aliénation': 'C2',\n",
       " 'aliéner': 'B1',\n",
       " 'allaitement': 'B2',\n",
       " 'allant': 'A2',\n",
       " 'allemand': 'C2',\n",
       " 'aller': 'A1',\n",
       " 'allergie': 'C1',\n",
       " 'allergique': 'B2',\n",
       " 'alliance': 'C1',\n",
       " 'allier': 'C2',\n",
       " 'allocataire': 'B1',\n",
       " 'allocation': 'B2',\n",
       " 'allocution': 'C2',\n",
       " 'allogène': 'C1',\n",
       " 'allongement': 'C2',\n",
       " 'allonger': 'A2',\n",
       " 'allongé': 'C1',\n",
       " 'allons': 'A2',\n",
       " 'allouer': 'C1',\n",
       " 'allumage': 'C2',\n",
       " 'allume': 'A2',\n",
       " 'allumer': 'C1',\n",
       " 'allumette': 'B1',\n",
       " 'allure': 'B1',\n",
       " 'allusif': 'A2',\n",
       " 'allusion': 'B2',\n",
       " 'allègre': 'A2',\n",
       " 'allécher': 'A2',\n",
       " 'allée': 'C1',\n",
       " 'alléger': 'C2',\n",
       " 'allégorie': 'C1',\n",
       " 'allégresse': 'B2',\n",
       " 'allô': 'A1',\n",
       " 'alors': 'A1',\n",
       " 'alpage': 'B1',\n",
       " 'alphabet': 'B2',\n",
       " 'alphabétique': 'B2',\n",
       " 'alphabétisation': 'C1',\n",
       " 'alpin': 'C1',\n",
       " 'alpiniste': 'B2',\n",
       " 'alsacien': 'B1',\n",
       " 'alternance': 'B2',\n",
       " 'alternatif': 'C2',\n",
       " 'alternative': 'C1',\n",
       " 'alterner': 'C1',\n",
       " 'altesse': 'A1',\n",
       " 'altier': 'B1',\n",
       " 'altitude': 'B1',\n",
       " 'altération': 'C2',\n",
       " 'altérer': 'B1',\n",
       " 'altérité': 'B2',\n",
       " 'aléa': 'C1',\n",
       " 'aléatoire': 'C2',\n",
       " 'amadouer': 'C1',\n",
       " 'amaigrir': 'B1',\n",
       " 'amande': 'A2',\n",
       " 'amant': 'B1',\n",
       " 'amateur': 'B1',\n",
       " 'amateurisme': 'B2',\n",
       " 'amazonien': 'C1',\n",
       " 'ambassade': 'A1',\n",
       " 'ambassadeur': 'B1',\n",
       " 'ambiance': 'B1',\n",
       " 'ambiant': 'C1',\n",
       " 'ambigu': 'C2',\n",
       " 'ambiguïté': 'C2',\n",
       " 'ambitieux': 'A2',\n",
       " 'ambition': 'C1',\n",
       " 'ambivalence': 'A2',\n",
       " 'ambivalent': 'B1',\n",
       " 'ambre': 'C2',\n",
       " 'ambrer': 'C1',\n",
       " 'ambulance': 'A2',\n",
       " 'ambulancier': 'A2',\n",
       " 'ambulant': 'B1',\n",
       " 'amende': 'B1',\n",
       " 'amener': 'A2',\n",
       " 'amer': 'C1',\n",
       " 'amertume': 'B1',\n",
       " 'ameublement': 'B1',\n",
       " 'ami': 'A1',\n",
       " 'amiable': 'B1',\n",
       " 'amical': 'C1',\n",
       " 'amicalement': 'A1',\n",
       " 'amidon': 'C1',\n",
       " 'amin': 'B1',\n",
       " 'amincir': 'B2',\n",
       " 'amitié': 'B1',\n",
       " 'amollir': 'B1',\n",
       " 'amont': 'B1',\n",
       " 'amorcer': 'C2',\n",
       " 'amortissement': 'C2',\n",
       " 'amour': 'A2',\n",
       " 'amoureux': 'A1',\n",
       " 'amphi': 'B1',\n",
       " 'amphibiens': 'C2',\n",
       " 'ample': 'B1',\n",
       " 'ampleur': 'C2',\n",
       " 'amplificateur': 'C1',\n",
       " 'amplifier': 'C1',\n",
       " 'ampoule': 'C1',\n",
       " 'amputer': 'B1',\n",
       " 'amusant': 'A1',\n",
       " 'amuse-gueule': 'B2',\n",
       " 'amusement': 'B1',\n",
       " 'amuser': 'A2',\n",
       " 'amuseur': 'A2',\n",
       " 'amène': 'A2',\n",
       " 'amèrement': 'C1',\n",
       " 'amélioration': 'C2',\n",
       " 'améliorer': 'C1',\n",
       " 'aménagement': 'B2',\n",
       " 'aménager': 'C2',\n",
       " 'aménageur': 'B1',\n",
       " 'américain': 'C1',\n",
       " 'américanisation': 'C1',\n",
       " 'américaniser': 'A2',\n",
       " 'amérindien': 'C1',\n",
       " 'an': 'C2',\n",
       " 'analgésie': 'C1',\n",
       " 'analogique': 'C1',\n",
       " 'analphabète': 'B2',\n",
       " 'analyse': 'C1',\n",
       " 'analyser': 'C1',\n",
       " 'analyste': 'C1',\n",
       " 'analytique': 'C2',\n",
       " 'ananas': 'A1',\n",
       " 'anarchique': 'C2',\n",
       " 'anarchiste': 'B1',\n",
       " 'anatomie': 'B1',\n",
       " 'anatomique': 'C2',\n",
       " 'ancestral': 'A2',\n",
       " 'anchois': 'A1',\n",
       " 'anchoïade': 'A1',\n",
       " 'ancien': 'C2',\n",
       " 'ancrage': 'C1',\n",
       " 'ancre': 'B1',\n",
       " 'ancrer': 'B2',\n",
       " 'ancêtre': 'B1',\n",
       " 'andalou': 'A2',\n",
       " 'andalouse': 'B1',\n",
       " 'andouillette': 'B2',\n",
       " 'androïde': 'A2',\n",
       " 'anecdote': 'C1',\n",
       " 'anecdotique': 'C1',\n",
       " 'anesthésie': 'C1',\n",
       " 'anesthésier': 'B2',\n",
       " 'anesthésique': 'C1',\n",
       " 'anesthésiste': 'C1',\n",
       " 'ange': 'B1',\n",
       " 'angine': 'C1',\n",
       " 'anglais': 'B2',\n",
       " 'anglaiser': 'A2',\n",
       " 'angle': 'A1',\n",
       " 'anglicisme': 'C1',\n",
       " 'anglo-américain': 'A2',\n",
       " 'anglo-saxon': 'C1',\n",
       " 'anglophone': 'C2',\n",
       " 'angoissant': 'B1',\n",
       " 'angoisse': 'C1',\n",
       " 'angoisser': 'C1',\n",
       " 'animal': 'A2',\n",
       " 'animateur': 'A2',\n",
       " 'animation': 'B1',\n",
       " 'animer': 'B1',\n",
       " 'annales': 'B1',\n",
       " 'annexe': 'A2',\n",
       " 'annexer': 'C1',\n",
       " 'anniversaire': 'A1',\n",
       " 'annonce': 'B2',\n",
       " 'annoncer': 'C1',\n",
       " 'annonceur': 'C1',\n",
       " 'annonciateur': 'B1',\n",
       " 'annuaire': 'A1',\n",
       " 'annuel': 'C1',\n",
       " 'annuellement': 'C2',\n",
       " 'annulaire': 'C1',\n",
       " 'annulation': 'A2',\n",
       " 'annuler': 'B1',\n",
       " 'année': 'C1',\n",
       " 'anodin': 'B2',\n",
       " 'anomalie': 'C1',\n",
       " 'anomie': 'C1',\n",
       " 'anonymat': 'C1',\n",
       " 'anonyme': 'B1',\n",
       " 'anophèle': 'C2',\n",
       " 'anormal': 'A2',\n",
       " 'anormalement': 'B1',\n",
       " 'antagonisme': 'C1',\n",
       " 'antagoniste': 'B2',\n",
       " 'antalgique': 'C1',\n",
       " 'antan': 'C2',\n",
       " 'antarctique': 'B1',\n",
       " 'antenne': 'C2',\n",
       " 'anthologie': 'B1',\n",
       " 'anthropologie': 'C1',\n",
       " 'anthropologique': 'C1',\n",
       " 'anthropologue': 'B2',\n",
       " 'anti-inflammatoire': 'C1',\n",
       " 'antibactérien': 'C1',\n",
       " 'antibiotique': 'C1',\n",
       " 'antichambre': 'B2',\n",
       " 'anticipation': 'C1',\n",
       " 'anticiper': 'B1',\n",
       " 'anticonformiste': 'A2',\n",
       " 'antifascisme': 'C2',\n",
       " 'antihéros': 'B2',\n",
       " 'antijeunes': 'B2',\n",
       " 'antillais': 'C2',\n",
       " 'antimicrobien': 'C1',\n",
       " 'antinucléaire': 'C2',\n",
       " 'antioxydant': 'C2',\n",
       " 'antipathie': 'B2',\n",
       " 'antipathique': 'B2',\n",
       " 'antipelliculaire': 'A2',\n",
       " 'antipode': 'B1',\n",
       " 'antiquaire': 'A1',\n",
       " 'antique': 'B1',\n",
       " 'antiquité': 'A1',\n",
       " 'antiraciste': 'B1',\n",
       " 'antistatique': 'C1',\n",
       " 'antitabac': 'C1',\n",
       " 'antiviral': 'C1',\n",
       " 'antivol': 'C1',\n",
       " 'antédiluvien': 'A2',\n",
       " 'antérieur': 'C2',\n",
       " 'anus': 'C1',\n",
       " 'anxieux': 'C1',\n",
       " 'anxiété': 'B1',\n",
       " 'anéantir': 'C1',\n",
       " 'août': 'A1',\n",
       " 'apaisement': 'B1',\n",
       " 'apaiser': 'A2',\n",
       " 'apanage': 'C1',\n",
       " 'apatride': 'B2',\n",
       " 'apercevoir': 'B1',\n",
       " 'aperçu': 'A2',\n",
       " 'apeurer': 'B2',\n",
       " 'apeuré': 'B1',\n",
       " 'aplanir': 'C2',\n",
       " 'apocalypse': 'B1',\n",
       " 'apocalyptique': 'B2',\n",
       " 'apocryphe': 'C1',\n",
       " 'apogée': 'C2',\n",
       " 'apothéose': 'C1',\n",
       " 'apparat': 'B1',\n",
       " 'apparaître': 'C1',\n",
       " 'appareil': 'C1',\n",
       " 'apparemment': 'B2',\n",
       " 'apparence': 'C2',\n",
       " 'apparent': 'B2',\n",
       " 'apparenter': 'C2',\n",
       " 'apparenté': 'B1',\n",
       " 'apparier': 'C1',\n",
       " 'apparition': 'C1',\n",
       " 'appartement': 'A1',\n",
       " 'appartenance': 'C1',\n",
       " 'appartenant': 'B1',\n",
       " 'appartenir': 'C1',\n",
       " 'appauvrir': 'B1',\n",
       " 'appauvrissement': 'C2',\n",
       " 'appel': 'C1',\n",
       " 'appelant': 'C1',\n",
       " 'appeler': 'A1',\n",
       " 'appellation': 'C1',\n",
       " 'appelé': 'C1',\n",
       " 'applaudir': 'B1',\n",
       " 'applaudissement': 'C2',\n",
       " 'applicable': 'B2',\n",
       " 'application': 'C1',\n",
       " 'appliquer': 'C1',\n",
       " 'apport': 'C2',\n",
       " 'apporter': 'C1',\n",
       " 'apposer': 'C1',\n",
       " 'apprenant': 'B1',\n",
       " 'apprendre': 'A2',\n",
       " 'apprenti': 'A1',\n",
       " 'apprentissage': 'C2',\n",
       " 'apprivoiser': 'A2',\n",
       " 'approbation': 'B1',\n",
       " 'approche': 'C1',\n",
       " 'approcher': 'B1',\n",
       " 'approfondir': 'C1',\n",
       " 'appropriation': 'C1',\n",
       " 'approprier': 'B2',\n",
       " 'approuver': 'C1',\n",
       " 'approvisionnement': 'C1',\n",
       " 'approvisionner': 'C1',\n",
       " 'approximatif': 'A2',\n",
       " 'approximation': 'B1',\n",
       " 'approximativement': 'B1',\n",
       " 'appréciable': 'C1',\n",
       " 'appréciation': 'C2',\n",
       " 'apprécier': 'C2',\n",
       " 'appréhender': 'C1',\n",
       " 'appréhension': 'B1',\n",
       " 'apprêter': 'B2',\n",
       " 'appui': 'C2',\n",
       " 'appuie-tête': 'C1',\n",
       " 'appuyer': 'C1',\n",
       " 'appât': 'B1',\n",
       " 'appétit': 'C2',\n",
       " 'après': 'B1',\n",
       " 'après-demain': 'B1',\n",
       " 'après-guerre': 'B1',\n",
       " 'après-midi': 'A1',\n",
       " 'après-vente': 'A2',\n",
       " 'aptitude': 'B2',\n",
       " 'apéritif': 'A1',\n",
       " 'apéro': 'B1',\n",
       " 'apôtre': 'C1',\n",
       " 'aquacole': 'B1',\n",
       " 'aquarium': 'A1',\n",
       " 'aquatique': 'A1',\n",
       " 'aqueduc': 'B1',\n",
       " 'arabe': 'C2',\n",
       " 'arabesque': 'B1',\n",
       " 'arabique': 'C1',\n",
       " 'araignée': 'B1',\n",
       " 'arak': 'B1',\n",
       " 'arbitraire': 'C1',\n",
       " 'arbitre': 'C1',\n",
       " 'arborer': 'C1',\n",
       " 'arboricole': 'B1',\n",
       " 'arbre': 'A2',\n",
       " 'arbuste': 'B2',\n",
       " 'arc': 'B1',\n",
       " 'arc-en-ciel': 'B1',\n",
       " 'arcade': 'B2',\n",
       " 'archaïque': 'C1',\n",
       " 'archevêché': 'C1',\n",
       " 'archevêque': 'A2',\n",
       " 'archipel': 'A2',\n",
       " 'architecte': 'B2',\n",
       " 'architectural': 'B1',\n",
       " 'architecture': 'B2',\n",
       " 'archives': 'C1',\n",
       " 'archéologie': 'C1',\n",
       " 'archéologique': 'B1',\n",
       " 'archéologue': 'A1',\n",
       " 'archétype': 'B2',\n",
       " 'ardent': 'B2',\n",
       " 'ardeur': 'C2',\n",
       " 'ardu': 'C2',\n",
       " 'argent': 'A2',\n",
       " 'argenterie': 'A2',\n",
       " 'argentin': 'A1',\n",
       " 'argenté': 'B1',\n",
       " 'argile': 'C1',\n",
       " 'argotique': 'C2',\n",
       " 'arguer': 'C2',\n",
       " 'argument': 'C1',\n",
       " 'argumentaire': 'C2',\n",
       " 'argumentation': 'B2',\n",
       " 'argumenter': 'C1',\n",
       " 'aride': 'A2',\n",
       " 'aristocrate': 'B1',\n",
       " 'aristocratie': 'B2',\n",
       " 'aristocratique': 'B1',\n",
       " 'arme': 'B1',\n",
       " 'armement': 'B1',\n",
       " 'armer': 'C1',\n",
       " 'armoire': 'B2',\n",
       " 'armoiries': 'B2',\n",
       " 'armure': 'A2',\n",
       " 'armé': 'C1',\n",
       " 'armée': 'C1',\n",
       " 'aromate': 'B1',\n",
       " 'aromatique': 'C1',\n",
       " 'aromatiser': 'A1',\n",
       " 'arpenter': 'C1',\n",
       " 'arrachage': 'C1',\n",
       " 'arrachement': 'C1',\n",
       " 'arracher': 'B1',\n",
       " 'arrangement': 'C1',\n",
       " 'arranger': 'B2',\n",
       " 'arrestation': 'A2',\n",
       " 'arrivage': 'B2',\n",
       " 'arrivant': 'C1',\n",
       " 'arriver': 'A2',\n",
       " 'arrivé': 'B2',\n",
       " 'arrière': 'B2',\n",
       " 'arrière-garde': 'C1',\n",
       " 'arrière-grand-père': 'A1',\n",
       " 'arrière-grands-parents': 'B2',\n",
       " 'arrière-plan': 'B1',\n",
       " 'arrogance': 'B1',\n",
       " 'arrogant': 'B1',\n",
       " 'arroger': 'C1',\n",
       " 'arrondir': 'B1',\n",
       " 'arrondissement': 'A1',\n",
       " 'arrosage': 'B1',\n",
       " 'arroser': 'C2',\n",
       " 'arroseur': 'B2',\n",
       " 'arrosoir': 'C1',\n",
       " 'arrêt': 'B2',\n",
       " 'arrêter': 'A2',\n",
       " 'arrêté': 'B2',\n",
       " 'arsenal': 'B2',\n",
       " 'art': 'B1',\n",
       " 'arthurien': 'A2',\n",
       " 'artichaut': 'B1',\n",
       " 'article': 'B2',\n",
       " 'articler': 'B2',\n",
       " 'articulaire': 'C1',\n",
       " 'articuler': 'C1',\n",
       " 'artifice': 'A1',\n",
       " 'artificiel': 'C2',\n",
       " 'artificiellement': 'C1',\n",
       " 'artisan': 'B1',\n",
       " 'artisanal': 'B1',\n",
       " 'artisanat': 'C2',\n",
       " 'artiste': 'B2',\n",
       " 'artistique': 'B2',\n",
       " 'artistiquer': 'B2',\n",
       " 'artère': 'C2',\n",
       " 'artériel': 'C2',\n",
       " 'arène': 'B2',\n",
       " 'arête': 'B2',\n",
       " 'as': 'B2',\n",
       " 'ascendance': 'B2',\n",
       " 'ascenseur': 'A1',\n",
       " 'ascension': 'B2',\n",
       " 'ascèse': 'B1',\n",
       " 'ascétisme': 'B1',\n",
       " 'asiatique': 'C1',\n",
       " 'asile': 'C1',\n",
       " 'asocial': 'B1',\n",
       " 'aspect': 'C2',\n",
       " 'aspirant': 'C1',\n",
       " 'aspirateur': 'A2',\n",
       " 'aspiration': 'C1',\n",
       " 'aspirer': 'C1',\n",
       " 'aspirine': 'A1',\n",
       " 'aspérité': 'C1',\n",
       " 'assagir': 'B1',\n",
       " 'assainissement': 'A2',\n",
       " 'assassin': 'B2',\n",
       " 'assassinat': 'B2',\n",
       " 'assassiner': 'B2',\n",
       " 'assaut': 'C1',\n",
       " 'assavoir': 'C1',\n",
       " 'assemblage': 'C1',\n",
       " 'assembler': 'C1',\n",
       " 'assemblée': 'C2',\n",
       " 'assener': 'B2',\n",
       " 'assentiment': 'C1',\n",
       " 'asseoir': 'A2',\n",
       " 'assertif': 'C2',\n",
       " 'asservir': 'B2',\n",
       " 'asservissant': 'B1',\n",
       " 'asservissement': 'C1',\n",
       " 'assez': 'B2',\n",
       " 'assidu': 'C2',\n",
       " 'assiduité': 'B1',\n",
       " 'assidûment': 'C2',\n",
       " 'assiette': 'B2',\n",
       " 'assigner': 'C1',\n",
       " 'assimilation': 'A2',\n",
       " 'assimiler': 'C1',\n",
       " 'assis': 'C1',\n",
       " 'assise': 'B2',\n",
       " 'assistanat': 'C1',\n",
       " 'assistance': 'B1',\n",
       " 'assistant': 'A1',\n",
       " 'assister': 'B1',\n",
       " 'assiéger': 'B1',\n",
       " 'associatif': 'C2',\n",
       " 'association': 'C2',\n",
       " 'associer': 'C2',\n",
       " 'associé': 'C2',\n",
       " 'assombrir': 'C1',\n",
       " 'assommer': 'C1',\n",
       " 'assortiment': 'B1',\n",
       " 'assortir': 'C1',\n",
       " 'assoupir': 'B1',\n",
       " 'assouplir': 'C1',\n",
       " 'assourdir': 'B2',\n",
       " 'assourdissant': 'A1',\n",
       " 'assouvir': 'C1',\n",
       " 'assujettir': 'C2',\n",
       " 'assumer': 'C2',\n",
       " 'assurance': 'C1',\n",
       " 'assurer': 'C2',\n",
       " 'assureur': 'C1',\n",
       " 'assurément': 'B2',\n",
       " 'assyrien': 'C1',\n",
       " 'assèchement': 'B1',\n",
       " 'assécher': 'C1',\n",
       " 'astiquer': 'B2',\n",
       " 'astre': 'A1',\n",
       " 'astreindre': 'C1',\n",
       " 'astrologie': 'C1',\n",
       " 'astrologue': 'B1',\n",
       " 'astronef': 'B1',\n",
       " 'astronome': 'C1',\n",
       " 'astronomie': 'B2',\n",
       " 'astronomique': 'A1',\n",
       " 'astrophysicien': 'B1',\n",
       " 'astuce': 'A2',\n",
       " 'astucieux': 'B1',\n",
       " 'astéroïde': 'C1',\n",
       " 'asymétrie': 'B2',\n",
       " 'asymétrique': 'C1',\n",
       " 'atavique': 'B2',\n",
       " 'atavisme': 'C2',\n",
       " 'atelier': 'C1',\n",
       " 'atermoyeur': 'B1',\n",
       " 'athlétique': 'C1',\n",
       " 'athlétisme': 'A2',\n",
       " 'athée': 'B1',\n",
       " 'athéisme': 'B1',\n",
       " 'athénien': 'B1',\n",
       " 'atlantique': 'C1',\n",
       " 'atmosphère': 'C1',\n",
       " 'atmosphérique': 'C2',\n",
       " 'atoll': 'B2',\n",
       " 'atome': 'C1',\n",
       " 'atomique': 'C1',\n",
       " 'atomiser': 'C2',\n",
       " 'atonie': 'C2',\n",
       " 'atout': 'C2',\n",
       " 'atroce': 'C1',\n",
       " 'atrocité': 'B2',\n",
       " 'attabler': 'B1',\n",
       " 'attachant': 'C1',\n",
       " 'attache': 'B2',\n",
       " 'attachement': 'C2',\n",
       " 'attacher': 'B1',\n",
       " 'attaquant': 'B1',\n",
       " 'attaque': 'B2',\n",
       " 'attaquer': 'C1',\n",
       " 'attarder': 'C1',\n",
       " 'atteindre': 'C1',\n",
       " 'atteinte': 'C2',\n",
       " 'attelage': 'B2',\n",
       " 'attendant': 'A2',\n",
       " 'attendre': 'A1',\n",
       " 'attentat': 'B1',\n",
       " 'attente': 'C1',\n",
       " 'attenter': 'B1',\n",
       " 'attentif': 'C2',\n",
       " 'attention': 'A1',\n",
       " 'attentionner': 'C1',\n",
       " 'attentionné': 'A1',\n",
       " 'attentiste': 'C1',\n",
       " 'attentivement': 'A2',\n",
       " 'atterrer': 'A2',\n",
       " 'atterrir': 'B1',\n",
       " 'atterrissage': 'A2',\n",
       " 'attestation': 'B1',\n",
       " 'attester': 'C2',\n",
       " 'attirail': 'B2',\n",
       " 'attirance': 'C2',\n",
       " 'attirant': 'B1',\n",
       " 'attirer': 'B1',\n",
       " 'attiser': 'C1',\n",
       " 'attitude': 'C1',\n",
       " 'attractif': 'C2',\n",
       " 'attraction': 'B1',\n",
       " 'attrait': 'B2',\n",
       " 'attrape': 'A2',\n",
       " 'attraper': 'B1',\n",
       " 'attribuable': 'B1',\n",
       " 'attribuer': 'C2',\n",
       " 'attribut': 'B2',\n",
       " 'attribution': 'B2',\n",
       " 'attrister': 'B2',\n",
       " 'attroupement': 'B1',\n",
       " 'attrouper': 'B2',\n",
       " 'atténuer': 'B2',\n",
       " 'atypique': 'C2',\n",
       " 'au': 'C2',\n",
       " 'au-dedans': 'B1',\n",
       " 'au-delà': 'C2',\n",
       " 'au-dessous': 'B1',\n",
       " 'au-dessus': 'B2',\n",
       " 'au-devant': 'B1',\n",
       " 'aubade': 'A2',\n",
       " 'aubain': 'C1',\n",
       " 'aubaine': 'B1',\n",
       " 'aube': 'B1',\n",
       " 'auberge': 'B1',\n",
       " 'aubergiste': 'B2',\n",
       " 'aubette': 'C1',\n",
       " 'aucun': 'C1',\n",
       " 'aucunement': 'C1',\n",
       " 'audace': 'B2',\n",
       " 'audacieux': 'C1',\n",
       " 'audience': 'C2',\n",
       " 'audiovisuel': 'C2',\n",
       " 'audit': 'C2',\n",
       " 'auditeur': 'A2',\n",
       " 'auditif': 'C1',\n",
       " 'audition': 'C2',\n",
       " 'auditoire': 'C1',\n",
       " 'auditorium': 'A2',\n",
       " 'augmentation': 'C2',\n",
       " 'augmenter': 'C2',\n",
       " 'augurer': 'B1',\n",
       " 'auguste': 'B2',\n",
       " \"aujourd'hui\": 'C2',\n",
       " 'aune': 'C2',\n",
       " 'auparavant': 'B1',\n",
       " 'auprès': 'B1',\n",
       " 'auquel': 'C1',\n",
       " 'aura': 'C1',\n",
       " 'aurore': 'B1',\n",
       " 'auréoler': 'C1',\n",
       " 'ausculter': 'B2',\n",
       " 'auspice': 'B1',\n",
       " 'aussi': 'B2',\n",
       " 'aussitôt': 'A2',\n",
       " 'austral': 'C1',\n",
       " 'australien': 'A1',\n",
       " 'autant': 'C1',\n",
       " 'autel': 'B1',\n",
       " 'auteur': 'C1',\n",
       " ...}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cefr_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d586723d-3967-4b14-856c-148a16c00922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'readability': {'word_count': 81,\n",
       "  'sentence_count': 3,\n",
       "  'syllable_count': 127,\n",
       "  'flesch_score': 64.2,\n",
       "  'complex_words': ['Algérie',\n",
       "   'refusé',\n",
       "   'Algériens',\n",
       "   'expulser',\n",
       "   'rejetée',\n",
       "   'autorités',\n",
       "   'algériennes',\n",
       "   'décidé',\n",
       "   'autorités',\n",
       "   'invitées',\n",
       "   'occurrence',\n",
       "   'préfectures',\n",
       "   'communiqué',\n",
       "   'ministère']},\n",
       " 'cefr': {'word_levels': {'algérie': 'Unknown',\n",
       "   'a': 'Unknown',\n",
       "   'refusé': 'Unknown',\n",
       "   'lundi': 'A1',\n",
       "   'mars': 'C2',\n",
       "   'la': 'A1',\n",
       "   'liste': 'C2',\n",
       "   'des': 'Unknown',\n",
       "   'noms': 'Unknown',\n",
       "   'une': 'Unknown',\n",
       "   'soixantaine': 'C1',\n",
       "   'algériens': 'Unknown',\n",
       "   'à': 'C2',\n",
       "   'expulser': 'C2',\n",
       "   'que': 'B2',\n",
       "   'france': 'Unknown',\n",
       "   'lui': 'A2',\n",
       "   'soumise': 'Unknown',\n",
       "   'il': 'A1',\n",
       "   'y': 'A1',\n",
       "   'quelques': 'Unknown',\n",
       "   'jours': 'Unknown',\n",
       "   'démarche': 'C2',\n",
       "   'rejetée': 'Unknown',\n",
       "   'sur': 'C1',\n",
       "   'forme': 'C2',\n",
       "   'et': 'A1',\n",
       "   'le': 'C2',\n",
       "   'fond': 'B1',\n",
       "   'par': 'A2',\n",
       "   'alger': 'Unknown',\n",
       "   'les': 'Unknown',\n",
       "   'autorités': 'Unknown',\n",
       "   'algériennes': 'Unknown',\n",
       "   'ont': 'Unknown',\n",
       "   'décidé': 'B1',\n",
       "   'de': 'C2',\n",
       "   'ne': 'B2',\n",
       "   'pas': 'B2',\n",
       "   'donner': 'B2',\n",
       "   'suite': 'B2',\n",
       "   'françaises': 'Unknown',\n",
       "   'invitées': 'Unknown',\n",
       "   'suivre': 'B2',\n",
       "   'canal': 'B2',\n",
       "   'usage': 'C1',\n",
       "   'en': 'B1',\n",
       "   'occurrence': 'C2',\n",
       "   'celui': 'C1',\n",
       "   'établi': 'Unknown',\n",
       "   'entre': 'C2',\n",
       "   'préfectures': 'Unknown',\n",
       "   'consulats': 'Unknown',\n",
       "   'précise': 'Unknown',\n",
       "   'un': 'B1',\n",
       "   'communiqué': 'C1',\n",
       "   'du': 'C2',\n",
       "   'ministère': 'C2',\n",
       "   'affaires': 'Unknown',\n",
       "   'étrangères': 'Unknown'},\n",
       "  'cefr_distribution': {'A1': 10,\n",
       "   'A2': 3,\n",
       "   'B1': 4,\n",
       "   'B2': 7,\n",
       "   'C1': 5,\n",
       "   'C2': 16,\n",
       "   'Unknown': 36},\n",
       "  'estimated_cefr_level': 'C2'}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = summarize_text_analysis(text, vocab_map=cefr_vocab)\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9ea87d1-0095-4f5f-bd0c-5ae4670fed12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting analyzer\n",
      "  Downloading analyzer-0.1.1.tar.gz (1.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting scipy>=0.13.0\n",
      "  Downloading scipy-1.15.2-cp310-cp310-win_amd64.whl (41.2 MB)\n",
      "     ---------------------------------------- 41.2/41.2 MB 5.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.5.1 in d:\\anaconda\\envs\\french_nlp\\lib\\site-packages (from analyzer) (1.24.3)\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\anaconda\\envs\\french_nlp\\lib\\site-packages (from analyzer) (4.13.4)\n",
      "Collecting SQLAlchemy>=0.8\n",
      "  Downloading sqlalchemy-2.0.40-cp310-cp310-win_amd64.whl (2.1 MB)\n",
      "     ---------------------------------------- 2.1/2.1 MB 9.0 MB/s eta 0:00:00\n",
      "Collecting pbr<1.7.0\n",
      "  Downloading pbr-1.6.0-py2.py3-none-any.whl (87 kB)\n",
      "     ---------------------------------------- 87.9/87.9 kB 5.2 MB/s eta 0:00:00\n",
      "Collecting mox\n",
      "  Downloading mox-0.5.3.tar.gz (32 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: pandas in d:\\anaconda\\envs\\french_nlp\\lib\\site-packages (from analyzer) (2.2.3)\n",
      "Collecting pyStock\n",
      "  Downloading pystock-0.1.6.tar.gz (14 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting analyzerdam>=0.1.0\n",
      "  Downloading analyzerdam-0.1.2.tar.gz (22 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting analyzerstrategies>=0.1.3\n",
      "  Downloading analyzerstrategies-0.1.5.tar.gz (8.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting googlefinance\n",
      "  Downloading googlefinance-0.7.tar.gz (2.5 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in d:\\anaconda\\envs\\french_nlp\\lib\\site-packages (from SQLAlchemy>=0.8->analyzer) (4.13.2)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\venka\\appdata\\roaming\\python\\python310\\site-packages (from SQLAlchemy>=0.8->analyzer) (1.1.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\anaconda\\envs\\french_nlp\\lib\\site-packages (from beautifulsoup4->analyzer) (2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\anaconda\\envs\\french_nlp\\lib\\site-packages (from pandas->analyzer) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anaconda\\envs\\french_nlp\\lib\\site-packages (from pandas->analyzer) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\anaconda\\envs\\french_nlp\\lib\\site-packages (from pandas->analyzer) (2025.2)\n",
      "Collecting alembic\n",
      "  Downloading alembic-1.15.2-py3-none-any.whl (231 kB)\n",
      "     ------------------------------------- 231.9/231.9 kB 14.8 MB/s eta 0:00:00\n",
      "Collecting py-moneyed\n",
      "  Downloading py_moneyed-3.0-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anaconda\\envs\\french_nlp\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->analyzer) (1.17.0)\n",
      "Collecting Mako\n",
      "  Downloading mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "     ---------------------------------------- 78.5/78.5 kB 4.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: babel>=2.8.0 in d:\\anaconda\\envs\\french_nlp\\lib\\site-packages (from py-moneyed->pyStock->analyzer) (2.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in d:\\anaconda\\envs\\french_nlp\\lib\\site-packages (from Mako->alembic->pyStock->analyzer) (3.0.2)\n",
      "Building wheels for collected packages: analyzer, analyzerdam, analyzerstrategies, mox, pyStock, googlefinance\n",
      "  Building wheel for analyzer (setup.py): started\n",
      "  Building wheel for analyzer (setup.py): finished with status 'done'\n",
      "  Created wheel for analyzer: filename=analyzer-0.1.1-py3-none-any.whl size=1943 sha256=8713d3c9970030269e951b2e95db57d0da6c791c389d60f8a6794a1e82d7aefc\n",
      "  Stored in directory: c:\\users\\venka\\appdata\\local\\pip\\cache\\wheels\\dc\\11\\3c\\b429634a62295c496434f04af5d43596ae30c7a15628fb9218\n",
      "  Building wheel for analyzerdam (setup.py): started\n",
      "  Building wheel for analyzerdam (setup.py): finished with status 'done'\n",
      "  Created wheel for analyzerdam: filename=analyzerdam-0.1.2-py2.py3-none-any.whl size=16347 sha256=171330d156076aa44750bfdc6dcde132170ace339b700c6ca416e7a77d717f70\n",
      "  Stored in directory: c:\\users\\venka\\appdata\\local\\pip\\cache\\wheels\\27\\1d\\cd\\7b4e4633ee9223132cf1fcd01395471b5e31c3cb5117d9946b\n",
      "  Building wheel for analyzerstrategies (setup.py): started\n",
      "  Building wheel for analyzerstrategies (setup.py): finished with status 'done'\n",
      "  Created wheel for analyzerstrategies: filename=analyzerstrategies-0.1.5-py2.py3-none-any.whl size=12065 sha256=0bae5b194771e72e30b51db1356fa55eb7e3b86d2b2667b228f63d502c9274e2\n",
      "  Stored in directory: c:\\users\\venka\\appdata\\local\\pip\\cache\\wheels\\e4\\13\\9e\\ebc33b04409e1c6e3da615813266ac45b0a28ea7d9d2152bd6\n",
      "  Building wheel for mox (setup.py): started\n",
      "  Building wheel for mox (setup.py): finished with status 'done'\n",
      "  Created wheel for mox: filename=mox-0.5.3-py3-none-any.whl size=21485 sha256=e927fabbe3a753676b09ec3f29759869507ca8c71b4ea07eb068835be181bc71\n",
      "  Stored in directory: c:\\users\\venka\\appdata\\local\\pip\\cache\\wheels\\2a\\49\\37\\c7884d57c2b2e5c3c148e0c155c9d7bb22a93edd120d15f5df\n",
      "  Building wheel for pyStock (setup.py): started\n",
      "  Building wheel for pyStock (setup.py): finished with status 'done'\n",
      "  Created wheel for pyStock: filename=pystock-0.1.6-py3-none-any.whl size=16394 sha256=035e6340f700bbea602ebc4e8247ba0f2eaeaa0541600ad63fec133b856676f4\n",
      "  Stored in directory: c:\\users\\venka\\appdata\\local\\pip\\cache\\wheels\\28\\71\\6b\\1ec41e974adb0d8aa51a3ddd4d44547938657c96fa1f2fcb2c\n",
      "  Building wheel for googlefinance (setup.py): started\n",
      "  Building wheel for googlefinance (setup.py): finished with status 'done'\n",
      "  Created wheel for googlefinance: filename=googlefinance-0.7-py3-none-any.whl size=2573 sha256=3083946d51e73ef470177183f5365f62d07fb23cd0376a45548250b245a1319b\n",
      "  Stored in directory: c:\\users\\venka\\appdata\\local\\pip\\cache\\wheels\\9b\\28\\0f\\4219d358c2e00c6f3b7b07102b424902938b83056a6b65e72f\n",
      "Successfully built analyzer analyzerdam analyzerstrategies mox pyStock googlefinance\n",
      "Installing collected packages: pbr, mox, googlefinance, analyzerstrategies, SQLAlchemy, scipy, py-moneyed, Mako, analyzerdam, alembic, pyStock, analyzer\n",
      "Successfully installed Mako-1.3.10 SQLAlchemy-2.0.40 alembic-1.15.2 analyzer-0.1.1 analyzerdam-0.1.2 analyzerstrategies-0.1.5 googlefinance-0.7 mox-0.5.3 pbr-1.6.0 py-moneyed-3.0 pyStock-0.1.6 scipy-1.15.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "77892d94-1924-479e-bdb8-9e4399b17ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [16/Apr/2025 17:02:26] \"POST /analyze HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import threading\n",
    "\n",
    "# Load vocab once\n",
    "cefr_vocab = load_cefr_vocab_from_flelex(\"FLELex_TreeTagger.csv\")\n",
    "\n",
    "# Define Flask app\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/analyze', methods=['POST'])\n",
    "def analyze():\n",
    "    data = request.get_json()\n",
    "    text = data.get(\"text\", \"\")\n",
    "    \n",
    "    if not text:\n",
    "        return jsonify({\"error\": \"No text provided\"}), 400\n",
    "\n",
    "    result = summarize_text_analysis(text, vocab_map=cefr_vocab)\n",
    "    return jsonify(result)\n",
    "\n",
    "# Function to run Flask without blocking\n",
    "def run_flask():\n",
    "    app.run(port=5000, debug=False, use_reloader=False)\n",
    "\n",
    "# Start Flask in background thread\n",
    "threading.Thread(target=run_flask).start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "846bc95b-b09f-4b39-b0e8-28f404ac3195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cefr': {'cefr_distribution': {'A1': 10, 'A2': 3, 'B1': 4, 'B2': 7, 'C1': 5, 'C2': 16, 'Unknown': 36}, 'estimated_cefr_level': 'C2', 'word_levels': {'a': 'Unknown', 'affaires': 'Unknown', 'alger': 'Unknown', 'algérie': 'Unknown', 'algériennes': 'Unknown', 'algériens': 'Unknown', 'autorités': 'Unknown', 'canal': 'B2', 'celui': 'C1', 'communiqué': 'C1', 'consulats': 'Unknown', 'de': 'C2', 'des': 'Unknown', 'donner': 'B2', 'du': 'C2', 'décidé': 'B1', 'démarche': 'C2', 'en': 'B1', 'entre': 'C2', 'et': 'A1', 'expulser': 'C2', 'fond': 'B1', 'forme': 'C2', 'france': 'Unknown', 'françaises': 'Unknown', 'il': 'A1', 'invitées': 'Unknown', 'jours': 'Unknown', 'la': 'A1', 'le': 'C2', 'les': 'Unknown', 'liste': 'C2', 'lui': 'A2', 'lundi': 'A1', 'mars': 'C2', 'ministère': 'C2', 'ne': 'B2', 'noms': 'Unknown', 'occurrence': 'C2', 'ont': 'Unknown', 'par': 'A2', 'pas': 'B2', 'précise': 'Unknown', 'préfectures': 'Unknown', 'que': 'B2', 'quelques': 'Unknown', 'refusé': 'Unknown', 'rejetée': 'Unknown', 'soixantaine': 'C1', 'soumise': 'Unknown', 'suite': 'B2', 'suivre': 'B2', 'sur': 'C1', 'un': 'B1', 'une': 'Unknown', 'usage': 'C1', 'y': 'A1', 'à': 'C2', 'établi': 'Unknown', 'étrangères': 'Unknown'}}, 'readability': {'complex_words': ['Algérie', 'refusé', 'Algériens', 'expulser', 'rejetée', 'autorités', 'algériennes', 'décidé', 'autorités', 'invitées', 'occurrence', 'préfectures', 'communiqué', 'ministère'], 'flesch_score': 71.05, 'sentence_count': 4, 'syllable_count': 127, 'word_count': 81}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "text = \" L’Algérie a refusé, lundi 17 mars, la liste des noms d’une soixantaine d’Algériens à expulser que la France lui a soumise il y a quelques jours, une démarche « rejetée sur la forme et le fond » par Alger. « Les autorités algériennes ont décidé de ne pas donner suite à la liste soumise par les autorités françaises » et les ont « invitées à suivre le canal d’usage, en l’occurrence celui établi entre les préfectures et les consulats », précise un communiqué du ministère des affaires étrangères.\"\n",
    "response = requests.post(\"http://127.0.0.1:5000/analyze\", json={\"text\": text})\n",
    "print(response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a190327-d77e-40e9-9d7f-2db2ee80209b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
